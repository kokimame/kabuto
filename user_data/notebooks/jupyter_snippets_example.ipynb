{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing bot data with Jupyter notebooks  \n",
    "\n",
    "You can analyze the results of backtests and trading history easily using Jupyter notebooks. A sample notebook is located at `user_data/notebooks/analysis_example.ipynb`.  \n",
    "\n",
    "## Pro tips  \n",
    "\n",
    "* See [jupyter.org](https://jupyter.org/documentation) for usage instructions.\n",
    "* Don't forget to start a jupyter notbook server from within your conda or venv environment or use [nb_conda_kernels](https://github.com/Anaconda-Platform/nb_conda_kernels)*\n",
    "* Copy the example notebook so your changes don't get clobbered with the next freqtrade update.\n",
    "\n",
    "## Fine print  \n",
    "\n",
    "Some tasks don't work especially well in notebooks. For example, anything using asyncronous exectution is a problem for Jupyter. Also, freqtrade's primary entry point is the shell cli, so using pure python in a notebook bypasses arguments that provide required parameters to functions.\n",
    "\n",
    "## Recommended workflow  \n",
    "\n",
    "| Task | Tool |  \n",
    "  --- | ---  \n",
    "Bot operations | CLI  \n",
    "Repetative tasks | shell scripts\n",
    "Data analysis & visualization | Notebook  \n",
    "\n",
    "1. Use the CLI to\n",
    "    * download historical data\n",
    "    * run a backtest\n",
    "    * run with real-time data\n",
    "    * export results  \n",
    "\n",
    "1. Collect these actions in shell scripts\n",
    "    * save complicated commands with arguments\n",
    "    * execute mult-step operations  \n",
    "    * automate testing strategies and prepareing data for analysis\n",
    "\n",
    "1. Use a notebook to\n",
    "    * import data\n",
    "    * munge and plot to generate insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example utility snippets for Jupyter notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change directory to root  \n",
    "\n",
    "Jupyter notebooks execute from the notebook directory. The following snippet searches for the project root, so relative paths remain consistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory\n",
    "# Modify this cell to insure that the output shows the correct path.\n",
    "# Define all paths relative to the project root shown in the cell output\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = \"somedir/freqtrade\"\n",
    "i=0\n",
    "try:\n",
    "    os.chdirdir(project_root)\n",
    "    assert Path('LICENSE').is_file()\n",
    "except:\n",
    "    while i<4 and (not Path('LICENSE').is_file()):\n",
    "        os.chdir(Path(Path.cwd(), '../'))\n",
    "        i+=1\n",
    "    project_root = Path.cwd()\n",
    "print(Path.cwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watch project for changes to code\n",
    "This scans the project for changes to code before Jupyter runs cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloads local code changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load existing objects into a Jupyter notebook\n",
    "\n",
    "These examples assume that you have already generated data using the cli. These examples will allow you to drill deeper into your results, and perform analysis which otherwise would make the output very difficult to digest due to information overload."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load backtest results into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load backtest results\n",
    "from freqtrade.data.btanalysis import load_backtest_data\n",
    "df = load_backtest_data(\"user_data/backtest_data/backtest-result.json\")\n",
    "\n",
    "# Show value-counts per pair\n",
    "df.groupby(\"pair\")[\"sell_reason\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load live trading results into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch trades from database\n",
    "from freqtrade.data.btanalysis import load_trades_from_db\n",
    "df = load_trades_from_db(\"sqlite:///tradesv3.sqlite\")\n",
    "\n",
    "# Display results\n",
    "df.groupby(\"pair\")[\"sell_reason\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load multiple configuration files\n",
    "This option can be useful to inspect the results of passing in multiple configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config from multiple files\n",
    "from freqtrade.configuration import Configuration\n",
    "config = Configuration.from_files([\"config1.json\", \"config2.json\"])\n",
    "\n",
    "# Show the config in memory\n",
    "import json\n",
    "print(json.dumps(config, indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load exchange data to a pandas dataframe\n",
    "\n",
    "This loads candle data to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data using values passed to function\n",
    "from pathlib import Path\n",
    "from freqtrade.data.history import load_pair_history\n",
    "\n",
    "ticker_interval = \"5m\"\n",
    "data_location = Path('user_data', 'data', 'bitrex')\n",
    "pair = \"BTC_USDT\"\n",
    "candles = load_pair_history(datadir=data_location,\n",
    "                            ticker_interval=ticker_interval,\n",
    "                            pair=pair)\n",
    "\n",
    "# Confirm success\n",
    "print(\"Loaded \" + str(len(candles)) + f\" rows of data for {pair} from {data_location}\")\n",
    "display(candles.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to submit an issue or Pull Request enhancing this document if you would like to share ideas on how to best analyze the data."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
